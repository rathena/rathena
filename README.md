<img src="doc/logo.png" align="right" height="90" />

# rAthena AI World - AI-Driven MMORPG Server with Autonomous NPCs

[![Production Ready](https://img.shields.io/badge/status-production%20ready-brightgreen.svg)](ai-autonomous-world/FINAL_SUMMARY.md)
[![AI Agents](https://img.shields.io/badge/AI%20agents-6%20specialized-blue.svg)](ai-autonomous-world/PHASE_2_COMPLETE.md)
[![LLM Providers](https://img.shields.io/badge/LLM%20providers-3%20(OpenAI%2C%20Anthropic%2C%20Google)-orange.svg)](ai-autonomous-world/ai-service/llm/)
![GitHub](https://img.shields.io/github/license/rathena/rathena.svg)

---

## Overview

rAthena AI World is an enhanced fork of rAthena MMORPG server that integrates multi-agent AI systems for autonomous NPC behavior, dynamic quest generation, and emergent gameplay. The system implements personality-driven NPCs using the Big Five personality model, AI-generated dialogue with long-term memory, and real-time economic simulation.

### Core Features

- **Personality-Driven NPCs**: Each NPC exhibits unique behavior based on the Big Five personality model (Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism) and nine moral alignments
- **AI-Generated Dialogue**: Adaptive conversations using LLM providers with persistent memory across sessions
- **Dynamic Quest System**: AI-generated quests with eight quest types and six difficulty levels, contextually tailored to player state and world events
- **Economic Simulation**: Supply and demand mechanics with realistic market fluctuations and emergent economic events
- **Faction System**: Dynamic reputation systems with seven faction types and eight reputation tiers
- **Autonomous World State**: NPCs make independent decisions and react to world events, creating emergent storylines

### Technical Architecture

The system consists of approximately 10,000 lines of production-grade Python and C++ code implementing:

- **6 Specialized AI Agents**: Dialogue, Decision, Memory, World, Quest, and Economy agents orchestrated via CrewAI framework
- **Long-term Memory Management**: Memori SDK integration with DragonflyDB fallback for persistent NPC memories and relationship tracking
- **Multi-Provider LLM Support**: OpenAI GPT-4, Anthropic Claude-3, and Google Gemini integration
- **Production-Grade Implementation**: Comprehensive error handling, verbose logging, async/await operations, and type-safe Pydantic models

---

## AI Autonomous World System Components

### Multi-Agent AI System
- **Dialogue Agent**: Generates personality-driven conversations with emotional context based on NPC traits
- **Decision Agent**: Processes NPC action decisions using personality parameters and current world state
- **Memory Agent**: Manages long-term memory storage and retrieval, tracks relationship values (-100 to +100 scale)
- **World Agent**: Analyzes world state data and generates dynamic events
- **Quest Agent**: Creates procedural quests using LLM providers (8 quest types, 6 difficulty levels)
- **Economy Agent**: Simulates market dynamics with supply/demand mechanics

### NPC Personality System
- **Big Five Personality Model**: Implements Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism traits
- **Moral Alignment System**: Nine alignment types from lawful good to chaotic evil
- **Behavioral Consistency**: NPCs maintain consistent behavior patterns across all interactions based on personality configuration
- **Emotional Response System**: Emotion generation matched to personality traits and situational context

### Dynamic Quest Generation
- **Quest Types**: Fetch, Kill, Escort, Delivery, Explore, Dialogue, Craft, Investigate
- **LLM-Generated Content**: Unique quest narratives generated by configured LLM provider
- **Contextual Generation**: Quest parameters based on NPC personality, player level, and current world events
- **Difficulty Scaling**: Six difficulty levels from trivial to epic

### Economic Simulation Engine
- **Supply and Demand Mechanics**: Price fluctuations calculated from market forces
- **Market Trend Analysis**: Rising, falling, stable, and volatile market condition states
- **Economic Event System**: Shortage, surplus, crisis, boom, and other economic events
- **Trade Analysis**: AI-driven market recommendations for player trading decisions

### Faction Reputation System
- **Faction Types**: Kingdom, Guild, Merchant, Religious, Military, Criminal, Neutral (7 types)
- **Reputation Tiers**: Hated, Hostile, Unfriendly, Neutral, Friendly, Honored, Revered, Exalted (8 tiers)
- **Dynamic Faction Relations**: Faction interactions, alliances, and conflicts based on world events
- **Reputation Effects**: Player standing modifies NPC behavior and quest availability

### Long-Term Memory Management
- **Persistent Memory Storage**: NPC memories retained across server sessions
- **Relationship Tracking System**: Interaction history affects NPC perception and behavior
- **Context-Aware Dialogue**: Historical conversation data influences future dialogue generation
- **Memori SDK Integration**: Advanced memory management with DragonflyDB fallback storage

---

## ðŸ”— Related Projects

### WARP P2P Client

The **[WARP-p2p-client](https://github.com/iskandarsulaili/WARP-p2p-client)** is the C++ WebRTC client implementation that connects to the rathena-AI-world P2P coordinator service. It enables hybrid P2P architecture where players can host game zones while maintaining centralized AI NPCs and authentication.

**Key Features**:
- WebRTC-based P2P connections for zone hosting
- Automatic host discovery and selection
- Secure communication with encryption
- Graceful fallback to main server
- Performance monitoring and host validation

**Integration**: The WARP client connects to the P2P coordinator service (`rathena-AI-world/p2p-coordinator`) via WebSocket signaling at `/api/signaling/ws`. See [P2P_INTEGRATION_ANALYSIS.md](../P2P_INTEGRATION_ANALYSIS.md) for detailed integration requirements.

**Architecture**: Hybrid P2P model where:
- **Centralized**: AI NPCs, authentication, anti-cheat, critical game logic
- **P2P**: Zone-based player interactions, reducing server load and latency

---

## ðŸ“š Documentation

### Core Documentation
- **[Architecture Overview](ai-autonomous-world/docs/ARCHITECTURE.md)** - System architecture and component interactions
- **[Configuration Guide](ai-autonomous-world/docs/CONFIGURATION.md)** - Complete configuration reference
- **[Free-Form Text Input](ai-autonomous-world/docs/FREE_FORM_TEXT_INPUT.md)** - Natural language player-NPC interactions
- **[GPU Acceleration](ai-autonomous-world/docs/GPU_ACCELERATION.md)** - GPU acceleration setup and optimization

### Feature Documentation
- **[NPC Movement System](ai-autonomous-world/FINAL_SUMMARY.md#requirement-3-npc-movement-capabilities)** - Autonomous NPC movement with pathfinding
- **[Memory System](ai-autonomous-world/PHASE_2_COMPLETE.md#2-memory-agent)** - Hyper-personalized per-player memory
- **[LLM Providers](ai-autonomous-world/FINAL_SUMMARY.md#requirement-1-azure-openai-support-as-default-provider)** - Multi-provider LLM support
- **[GPU Acceleration](ai-autonomous-world/docs/GPU_ACCELERATION.md)** - 10-100x faster inference with GPU support

### Implementation Guides
- **[Phase 1: Infrastructure](ai-autonomous-world/PHASE_1_COMPLETE.md)** - Bridge layer and database setup
- **[Phase 2: AI Agents](ai-autonomous-world/PHASE_2_COMPLETE.md)** - Multi-agent system implementation
- **[Bridge Layer](ai-autonomous-world/BRIDGE_LAYER_IMPLEMENTATION.md)** - C++ HTTP bridge integration

### Quick Reference
- **[API Endpoints](ai-autonomous-world/docs/FREE_FORM_TEXT_INPUT.md#api-documentation)** - REST API reference
- **[Troubleshooting](ai-autonomous-world/docs/FREE_FORM_TEXT_INPUT.md#troubleshooting)** - Common issues and solutions
- **[NPC Scripts](npc/custom/ai-world/README.md)** - rAthena NPC script examples

---

## Quick Start Guide - AI System

### System Requirements

#### Minimum Requirements
- Python 3.12 or higher
- DragonflyDB (Redis-compatible) or Redis 7.0+
- LLM API Keys: At least one of OpenAI, Anthropic, or Google Gemini
- 8GB RAM minimum (16GB recommended for production)

#### Optional: GPU Acceleration
- **NVIDIA GPU**: GTX 1060 (6GB VRAM) or higher, CUDA 11.8+
- **Apple Silicon**: M1/M2/M3 with 16GB+ unified memory
- **AMD GPU**: RX 6000/7000 series with ROCm 5.4+
- **Performance**: 10-100x faster LLM inference, 5-20x faster vector search

### Docker Deployment

```bash
cd ai-autonomous-world

# Configure environment
cp ai-service/.env.example ai-service/.env
# Edit .env with your API keys

# Start all services
docker-compose up -d

# Verify deployment
curl http://localhost:8000/health
```

### Manual Installation

```bash
cd ai-autonomous-world

# Activate virtual environment
source venv/bin/activate

# Start DragonflyDB
dragonfly --port 6379 &

# Start AI Service
cd ai-service
python main.py
```

### Documentation Resources

- [FINAL_SUMMARY.md](ai-autonomous-world/FINAL_SUMMARY.md) - Complete AI system overview
- [DEPLOYMENT_GUIDE.md](ai-autonomous-world/DEPLOYMENT_GUIDE.md) - Detailed deployment instructions
- [ARCHITECTURE.md](ai-autonomous-world/docs/ARCHITECTURE.md) - System architecture details
- [PHASE_2_COMPLETE.md](ai-autonomous-world/PHASE_2_COMPLETE.md) - Agent system documentation

### API Documentation

Interactive API documentation available at `http://localhost:8000/docs` when AI Service is running.

---

## Technical Specifications

- **Production Implementation**: Comprehensive error handling and verbose logging throughout codebase
- **Cloud-Optimized Deployment**: 3.5GB memory footprint without local LLM models
- **Horizontal Scaling**: Docker-based deployment supports horizontal scaling
- **Asynchronous Operations**: Non-blocking async/await pattern implementation
- **Type Safety**: Pydantic models for all data structures and API contracts
- **Test Coverage**: Integration and unit tests included

---

## System Architecture

```
rAthena Game Server (C++)
         â†“
Bridge Layer (C++ HTTP Controller)
         â†“
AI Service Layer (Python/FastAPI)
    â”œâ”€â”€ Agent Orchestrator (CrewAI)
    â”‚   â”œâ”€â”€ Dialogue Agent
    â”‚   â”œâ”€â”€ Decision Agent
    â”‚   â”œâ”€â”€ Memory Agent
    â”‚   â”œâ”€â”€ World Agent
    â”‚   â”œâ”€â”€ Quest Agent
    â”‚   â””â”€â”€ Economy Agent
    â”œâ”€â”€ API Routers
    â””â”€â”€ LLM Providers
         â†“
State Management (DragonflyDB/Redis)
         â†“
LLM Provider Layer (OpenAI/Anthropic/Google)
```

---

## About rAthena Base Project

rAthena is a collaborative software development project for creating a massively multiplayer online role playing game (MMORPG) server package. Written in C++, the program provides NPCs, warps, and modifications. The project is managed by volunteers worldwide with community QA and support. rAthena is a continuation of the eAthena project.

rAthena AI World extends the base rAthena server with an AI-driven autonomous world system for enhanced NPC behavior and emergent gameplay.

### rAthena Resources

[Forum](https://rathena.org/board)|[Discord](https://rathena.org/discord)|[Wiki](https://github.com/rathena/rathena/wiki)|[FluxCP](https://github.com/rathena/FluxCP)|[Crowdfunding](https://rathena.org/board/crowdfunding/)|[Fork and Pull Request Q&A](https://rathena.org/board/topic/86913-pull-request-qa/)
--------|--------|--------|--------|--------|--------

---

### Table of Contents
1. [AI System Prerequisites](#1-ai-system-prerequisites)
2. [rAthena Prerequisites](#2-rathena-prerequisites)
3. [Installation](#3-installation)
4. [Troubleshooting](#4-troubleshooting)
5. [More Documentation](#5-more-documentation)
6. [How to Contribute](#6-how-to-contribute)
7. [License](#7-license)

---

## 1. AI System Prerequisites

The AI Autonomous World System requires additional components beyond the base rAthena server.

### Hardware Requirements
Hardware Type | Minimum | Recommended
------|------|------
CPU | 2 Cores | 4 Cores
RAM | 8 GB | 16 GB
Disk Space | 5 GB | 10 GB

### Software Requirements
Application | Version | Purpose
------|------|------
Python | 3.12+ | AI Service runtime
DragonflyDB | Latest | State management (Redis-compatible)
Docker | 20.10+ | Optional - for containerized deployment

### LLM Provider API Keys
At least one LLM provider API key is required:
- OpenAI (GPT-4)
- Anthropic (Claude-3-Sonnet)
- Google (Gemini-Pro)

Optional:
- Memori SDK API key for enhanced memory management

### Python Dependencies
Python dependencies are managed via `requirements-cloud.txt` in the `ai-autonomous-world/ai-service/` directory. The system is cloud-optimized (3.5GB footprint) and does not require local LLM models.

---

## 2. rAthena Base Server Prerequisites
The base rAthena server requires specific tools and applications depending on the operating system.

### Hardware Requirements
Hardware Type | Minimum | Recommended
------|------|------
CPU | 1 Core | 2 Cores
RAM | 1 GB | 2 GB
Disk Space | 300 MB | 500 MB

### Operating System and Compiler
Operating System | Compiler
------|------
Linux  | [gcc-6 or newer](https://www.gnu.org/software/gcc/gcc-6/) / [Make](https://www.gnu.org/software/make/)
Windows | [MS Visual Studio 2017 or newer](https://www.visualstudio.com/downloads/)

### Required Software
Application | Name
------|------
Database | [MySQL 5 or newer](https://www.mysql.com/downloads/) / [MariaDB 5 or newer](https://downloads.mariadb.org/)
Git | [Windows](https://gitforwindows.org/) / [Linux](https://git-scm.com/download/linux)

### Optional Software
Application | Name
------|------
Database | [MySQL Workbench 5 or newer](http://www.mysql.com/downloads/workbench/)

---

## 3. Installation

### AI System Installation

Complete setup guide: [ai-autonomous-world/DEPLOYMENT_GUIDE.md](ai-autonomous-world/DEPLOYMENT_GUIDE.md)

Docker installation:
```bash
cd ai-autonomous-world
cp ai-service/.env.example ai-service/.env
# Edit .env with your LLM API keys
docker-compose up -d
```

Manual installation:
```bash
cd ai-autonomous-world
source venv/bin/activate
dragonfly --port 6379 &
cd ai-service
python main.py
```

### rAthena Base Server Installation
  * [Windows](https://github.com/rathena/rathena/wiki/Install-on-Windows)
  * [CentOS](https://github.com/rathena/rathena/wiki/Install-on-Centos)
  * [Debian](https://github.com/rathena/rathena/wiki/Install-on-Debian)
  * [FreeBSD](https://github.com/rathena/rathena/wiki/Install-on-FreeBSD)

Note: The AI Bridge Layer is integrated into the rAthena web server. Compile with `--enable-webserver` flag.

---

## 4. Troubleshooting

### AI System Troubleshooting

AI Service startup issues:
```bash
# Check logs
docker-compose logs ai-service
# Or for manual setup
tail -f ai-service/logs/ai-service.log
```

DragonflyDB connection issues:
```bash
# Test connection
redis-cli ping
# Check if running
ps aux | grep dragonfly
```

Bridge Layer compilation errors:
```bash
# Ensure web server is enabled
./configure --enable-webserver
make clean && make server
```

Complete troubleshooting guide: [ai-autonomous-world/DEPLOYMENT_GUIDE.md](ai-autonomous-world/DEPLOYMENT_GUIDE.md)

### rAthena Base Server Troubleshooting

For rAthena server startup issues, check console output for error messages. Most support issues can be resolved by examining error messages. Additional support available at the [wiki](https://github.com/rathena/rathena/wiki) or [forums](https://rathena.org/forum).

---

## 5. More Documentation

### AI System Documentation

- [FINAL_SUMMARY.md](ai-autonomous-world/FINAL_SUMMARY.md) - Complete project overview and statistics
- [DEPLOYMENT_GUIDE.md](ai-autonomous-world/DEPLOYMENT_GUIDE.md) - Comprehensive deployment instructions
- [ARCHITECTURE.md](ai-autonomous-world/docs/ARCHITECTURE.md) - System architecture and design
- [PHASE_2_COMPLETE.md](ai-autonomous-world/PHASE_2_COMPLETE.md) - Agent system details
- [TESTING_GUIDE.md](ai-autonomous-world/TESTING_GUIDE.md) - Testing procedures
- API Documentation: `http://localhost:8000/docs` (when AI Service is running)

### rAthena Base Server Documentation
The `/doc/` directory contains help files and sample NPC scripts with detailed explanations of NPC script commands, atcommands (@), group permissions, item bonuses, and packet structures.

---

## 6. How to Contribute

### Contributing to AI System
Contributions to the AI Autonomous World System:
- New AI agents
- Agent behavior improvements
- Additional LLM providers
- Economic simulation enhancements
- Faction system extensions

Review the architecture documentation before submitting pull requests. Include comprehensive tests with all contributions.

### Contributing to rAthena Base
Contribution guidelines for the base rAthena project: [CONTRIBUTING.md](https://github.com/rathena/rathena/blob/master/.github/CONTRIBUTING.md)

---

## 7. License

### AI Autonomous World System
The AI enhancement system (located in `ai-autonomous-world/`) is licensed under [GNU General Public License v3.0](LICENSE).

### rAthena Base
Copyright (c) rAthena Development Team - Licensed under [GNU General Public License v3.0](https://github.com/rathena/rathena/blob/master/LICENSE)

---

## Credits

### AI Autonomous World System
- Architecture & Implementation: Multi-agent AI system with CrewAI orchestration
- Technologies: Python 3.12, FastAPI, CrewAI, Memori SDK, DragonflyDB, OpenAI, Anthropic, Google Gemini
- Codebase: Approximately 10,000 lines of production-grade Python and C++
- Status: Production-ready with comprehensive testing

### rAthena Base Project
- Original Project: [rAthena](https://github.com/rathena/rathena)
- Community: rAthena Development Team and contributors worldwide
- Foundation: Continuation of the eAthena project

---

## Getting Started

1. Clone this repository
2. Set up the AI system: Follow [ai-autonomous-world/DEPLOYMENT_GUIDE.md](ai-autonomous-world/DEPLOYMENT_GUIDE.md)
3. Install rAthena base: Follow standard rAthena installation guides above
4. Configure LLM API keys in `ai-autonomous-world/ai-service/.env`
5. Launch the server
