# ğŸ§ª AI Autonomous World Service - Test Suite Documentation

Complete test suite for the AI-MMORPG world service with comprehensive coverage across routers, utilities, integration, performance, and security.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Test Structure](#test-structure)
- [Quick Start](#quick-start)
- [Test Categories](#test-categories)
- [Running Tests](#running-tests)
- [Coverage Requirements](#coverage-requirements)
- [Best Practices](#best-practices)
- [CI/CD Integration](#cicd-integration)
- [Troubleshooting](#troubleshooting)

## ğŸ¯ Overview

**Total Test Files**: 31  
**Test Framework**: pytest 9.0.0  
**Coverage Tool**: pytest-cov  
**Performance Tool**: pytest-benchmark  
**Async Support**: pytest-asyncio

### Test Statistics

- **Router Tests**: 14 files (~4,500 lines)
- **Utility Tests**: 8 files (~4,000 lines)
- **Integration Tests**: 3 files (~1,500 lines)
- **Performance Tests**: 3 files (~1,450 lines)
- **Security Tests**: 3 files (~1,600 lines)

**Total Lines of Test Code**: ~13,000+

## ğŸ“ Test Structure

```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ conftest.py                  # Global fixtures and configuration
â”œâ”€â”€ README.md                    # This file
â”‚
â”œâ”€â”€ routers/                     # FastAPI endpoint tests (14 files)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_npc.py             # NPC registration, state, actions
â”‚   â”œâ”€â”€ test_player.py          # Player interactions, dialogue
â”‚   â”œâ”€â”€ test_quest.py           # Quest management, completion
â”‚   â”œâ”€â”€ test_world.py           # World state, environment
â”‚   â”œâ”€â”€ test_economy.py         # Market, transactions
â”‚   â”œâ”€â”€ test_faction.py         # Faction management
â”‚   â”œâ”€â”€ test_relationship.py    # NPC-Player relationships
â”‚   â”œâ”€â”€ test_chat_command.py    # Chat command processing
â”‚   â”œâ”€â”€ test_gift.py            # Gift mechanics
â”‚   â”œâ”€â”€ test_mvp.py             # MVP spawning, behavior
â”‚   â”œâ”€â”€ test_navigation.py      # Pathfinding, maps
â”‚   â”œâ”€â”€ test_npc_actions.py     # NPC action execution
â”‚   â”œâ”€â”€ test_npc_movement.py    # Movement mechanics
â”‚   â””â”€â”€ test_emotional_state.py # Emotional AI
â”‚
â”œâ”€â”€ utils/                       # Utility function tests (8 files)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_movement_actions.py    # Movement calculations
â”‚   â”œâ”€â”€ test_validators.py          # Input validation
â”‚   â”œâ”€â”€ test_error_handlers.py      # Error handling
â”‚   â”œâ”€â”€ test_json_utils.py          # JSON serialization
â”‚   â”œâ”€â”€ test_request_batcher.py     # Request batching
â”‚   â”œâ”€â”€ test_circuit_breaker.py     # Circuit breaker pattern
â”‚   â”œâ”€â”€ test_correlation.py         # Correlation IDs
â”‚   â””â”€â”€ test_gpu_manager.py         # GPU management
â”‚
â”œâ”€â”€ integration/                 # End-to-end tests (3 files)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_integration_e2e.py    # Full workflows
â”‚   â”œâ”€â”€ test_integration_db.py     # Database operations
â”‚   â””â”€â”€ test_integration_llm.py    # LLM provider fallback
â”‚
â”œâ”€â”€ performance/                 # Performance tests (3 files)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_performance_latency.py     # <500ms p95
â”‚   â”œâ”€â”€ test_performance_throughput.py  # Requests/second
â”‚   â””â”€â”€ test_performance_concurrency.py # 100+ concurrent
â”‚
â””â”€â”€ security/                    # Security tests (3 files)
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_security_auth.py        # Auth bypass attempts
    â”œâ”€â”€ test_security_injection.py   # Injection attacks
    â””â”€â”€ test_security_dos.py         # DoS protection
```

## ğŸš€ Quick Start

### Prerequisites

```bash
# Install test dependencies
pip install -r requirements-test.txt

# Or install specific packages
pip install pytest pytest-asyncio pytest-cov pytest-benchmark
```

### Run All Tests

```bash
# Run entire test suite
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=. --cov-report=html --cov-report=term

# Run with markers
pytest tests/ -v -m "not slow"
```

### Run Specific Categories

```bash
# Router tests only
pytest tests/routers/ -v

# Integration tests
pytest tests/integration/ -v -m integration

# Performance tests
pytest tests/performance/ --benchmark-only

# Security tests
pytest tests/security/ -v -m security
```

## ğŸ“Š Test Categories

### 1. Router Tests (Unit)

**Purpose**: Test FastAPI endpoints with mocked dependencies

**Coverage**:
- âœ… Request/response validation
- âœ… Error handling (400, 404, 500)
- âœ… Authentication/authorization
- âœ… Business logic
- âœ… Edge cases

**Example**:
```bash
pytest tests/routers/test_npc.py::TestNPCRegistration -v
```

### 2. Utility Tests (Unit)

**Purpose**: Test utility functions and helper classes

**Coverage**:
- âœ… Input validation
- âœ… Data transformations
- âœ… Error handling
- âœ… Performance optimizations
- âœ… Thread safety

**Example**:
```bash
pytest tests/utils/test_validators.py -v
```

### 3. Integration Tests

**Purpose**: Test complete workflows across multiple components

**Coverage**:
- âœ… End-to-end player interactions
- âœ… Database transaction integrity
- âœ… LLM provider fallback mechanisms
- âœ… Error propagation
- âœ… Data consistency

**Example**:
```bash
pytest tests/integration/test_integration_e2e.py -v
```

### 4. Performance Tests

**Purpose**: Validate performance requirements

**Requirements**:
- âœ… Latency: p95 < 500ms
- âœ… Throughput: > 100 requests/second
- âœ… Concurrency: Handle 100+ simultaneous requests

**Example**:
```bash
pytest tests/performance/ --benchmark-only --benchmark-sort=mean
```

### 5. Security Tests

**Purpose**: Validate security measures and prevent vulnerabilities

**Coverage**:
- âœ… Authentication bypass prevention
- âœ… SQL/NoSQL injection resistance
- âœ… XSS protection
- âœ… Command injection prevention
- âœ… DoS protection
- âœ… Rate limiting

**Example**:
```bash
pytest tests/security/test_security_injection.py -v
```

## ğŸ¯ Coverage Requirements

### Minimum Coverage Targets

- **Overall**: 85%
- **Routers**: 90%
- **Utilities**: 95%
- **Models**: 80%
- **Agents**: 75%

### Generate Coverage Report

```bash
# HTML report
pytest tests/ --cov=. --cov-report=html
open htmlcov/index.html

# Terminal report
pytest tests/ --cov=. --cov-report=term-missing

# XML report (for CI/CD)
pytest tests/ --cov=. --cov-report=xml
```

### Coverage by Module

```bash
# Specific module coverage
pytest tests/routers/ --cov=routers --cov-report=term

# With branch coverage
pytest tests/ --cov=. --cov-branch --cov-report=term
```

## ğŸ’¡ Best Practices

### 1. Test Naming Convention

```python
# âœ… Good
def test_register_npc_success(client, sample_npc_data):
    """Test successful NPC registration"""
    
def test_register_npc_duplicate(client, sample_npc_data):
    """Test duplicate NPC registration rejection"""

# âŒ Bad
def test_npc1(client):
    pass
```

### 2. Use Fixtures

```python
@pytest.fixture
def sample_npc_data():
    """Reusable NPC test data"""
    return {
        "npc_id": "test_001",
        "name": "Test NPC",
        "level": 50
    }
```

### 3. Mock External Dependencies

```python
def test_llm_call(client):
    with patch('llm.get_llm_provider') as mock_llm:
        mock_llm.return_value.generate = AsyncMock(return_value="Response")
        # Test logic here
```

### 4. Use Markers

```python
@pytest.mark.asyncio
@pytest.mark.slow
@pytest.mark.integration
async def test_complex_workflow():
    # Test implementation
```

### 5. Arrange-Act-Assert Pattern

```python
def test_example():
    # Arrange
    data = {"key": "value"}
    
    # Act
    result = process_data(data)
    
    # Assert
    assert result["status"] == "success"
```

## ğŸ”§ Running Specific Tests

### By File

```bash
pytest tests/routers/test_npc.py -v
```

### By Class

```bash
pytest tests/routers/test_npc.py::TestNPCRegistration -v
```

### By Function

```bash
pytest tests/routers/test_npc.py::TestNPCRegistration::test_register_npc_success -v
```

### By Marker

```bash
# Run only fast tests
pytest tests/ -v -m "not slow"

# Run only async tests
pytest tests/ -v -m asyncio

# Run integration tests
pytest tests/ -v -m integration

# Run performance tests
pytest tests/ -v -m performance

# Run security tests
pytest tests/ -v -m security
```

### By Keyword

```bash
# Tests containing "npc"
pytest tests/ -k "npc" -v

# Tests NOT containing "slow"
pytest tests/ -k "not slow" -v
```

## ğŸ”„ CI/CD Integration

### GitHub Actions Example

```yaml
name: Test Suite

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        pip install -r requirements-test.txt
    
    - name: Run tests with coverage
      run: |
        pytest tests/ --cov=. --cov-report=xml --cov-report=term
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
```

### GitLab CI Example

```yaml
test:
  image: python:3.11
  script:
    - pip install -r requirements-test.txt
    - pytest tests/ --cov=. --cov-report=xml --cov-report=term
  coverage: '/TOTAL.*\s+(\d+%)$/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
```

## ğŸ› Troubleshooting

### Common Issues

#### 1. Import Errors

```bash
# Add parent directory to Python path
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
pytest tests/
```

#### 2. Async Tests Failing

```bash
# Ensure pytest-asyncio is installed
pip install pytest-asyncio

# Use proper async markers
@pytest.mark.asyncio
async def test_async_function():
    result = await async_operation()
    assert result is not None
```

#### 3. Database Connection Issues

```bash
# Use test database fixtures
@pytest.fixture
async def test_db():
    # Setup test database
    db = TestDatabase()
    await db.connect()
    yield db
    await db.disconnect()
```

#### 4. Mock Not Working

```python
# Correct import path
with patch('routers.npc.db.client') as mock_db:  # âœ…
    # Not patch('database.db.client')  # âŒ
```

#### 5. Performance Tests Inconsistent

```bash
# Use warmup and multiple rounds
pytest tests/performance/ --benchmark-warmup=on --benchmark-min-rounds=10
```

### Debug Mode

```bash
# Verbose output
pytest tests/ -vv

# Show print statements
pytest tests/ -s

# Stop on first failure
pytest tests/ -x

# Drop into debugger on failure
pytest tests/ --pdb

# Show local variables on failure
pytest tests/ -l
```

### Parallel Execution

```bash
# Install pytest-xdist
pip install pytest-xdist

# Run tests in parallel
pytest tests/ -n auto

# Specific number of workers
pytest tests/ -n 4
```

## ğŸ“ˆ Test Metrics

### Performance Benchmarks

| Endpoint | p50 | p95 | p99 | Target |
|----------|-----|-----|-----|--------|
| Health | 5ms | 10ms | 15ms | <50ms |
| NPC Dialogue | 200ms | 450ms | 500ms | <500ms |
| Quest Assign | 150ms | 400ms | 480ms | <500ms |
| World State | 100ms | 300ms | 450ms | <500ms |

### Security Test Coverage

| Category | Tests | Coverage |
|----------|-------|----------|
| Authentication | 20+ | 100% |
| Injection | 25+ | 95% |
| DoS Protection | 20+ | 100% |
| XSS Prevention | 15+ | 100% |

## ğŸ”— Related Documentation

- [Main README](../README.md)
- [API Documentation](../docs/API.md)
- [Architecture Guide](../docs/ARCHITECTURE.md)
- [Configuration Guide](../docs/CONFIGURATION.md)

## ğŸ¤ Contributing

### Adding New Tests

1. Create test file in appropriate directory
2. Follow naming convention: `test_*.py`
3. Use existing fixtures from `conftest.py`
4. Add appropriate markers
5. Keep files < 500 lines
6. Document test purpose in docstrings
7. Run test suite to ensure no regressions

### Test Review Checklist

- [ ] Tests pass locally
- [ ] Coverage maintained/improved
- [ ] No hardcoded secrets
- [ ] Proper use of fixtures
- [ ] Appropriate markers applied
- [ ] Clear test names and docstrings
- [ ] Edge cases covered
- [ ] Performance considered

## ğŸ“ Support

For test-related issues:
- Check [Troubleshooting](#troubleshooting) section
- Review existing test examples
- Consult pytest documentation: https://docs.pytest.org/
- Open an issue with test failure details

---

**Last Updated**: 2025-11-22  
**Test Suite Version**: 1.0.0  
**Pytest Version**: 9.0.0