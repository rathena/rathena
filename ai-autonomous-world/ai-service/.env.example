# AI Service Environment Configuration
# Copy this file to .env and fill in your actual values

# ============================================================================
# SERVICE CONFIGURATION
# ============================================================================
SERVICE_HOST=0.0.0.0
SERVICE_PORT=8000
SERVICE_ENV=development
LOG_LEVEL=DEBUG

# ============================================================================
# DRAGONFLY DB (Redis-compatible)
# ============================================================================
DRAGONFLY_HOST=localhost
DRAGONFLY_PORT=6379
DRAGONFLY_PASSWORD=
DRAGONFLY_DB=0

# ============================================================================
# LLM PROVIDER CONFIGURATION
# ============================================================================

# Primary LLM Provider (azure_openai, openai, ollama, deepseek, gemini, claude)
PRIMARY_LLM_PROVIDER=azure_openai

# Azure OpenAI (Recommended for production)
AZURE_OPENAI_API_KEY=your-azure-openai-api-key-here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-ada-002

# OpenAI (Alternative)
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Ollama (Local development)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# DeepSeek (Cost-effective alternative)
DEEPSEEK_API_KEY=your-deepseek-api-key-here
DEEPSEEK_BASE_URL=https://api.deepseek.com
DEEPSEEK_MODEL=deepseek-chat

# Google Gemini
GOOGLE_API_KEY=your-google-api-key-here
GEMINI_MODEL=gemini-pro

# Anthropic Claude
ANTHROPIC_API_KEY=your-anthropic-api-key-here
CLAUDE_MODEL=claude-3-opus-20240229

# ============================================================================
# LLM OPTIMIZATION
# ============================================================================
LLM_CACHE_ENABLED=true
LLM_CACHE_TTL=3600
LLM_BATCH_SIZE=10
LLM_RATE_LIMIT_RPM=60
LLM_TIMEOUT=30

# ============================================================================
# CREWAI CONFIGURATION
# ============================================================================
CREWAI_VERBOSE=true
CREWAI_MAX_ITERATIONS=10

# ============================================================================
# MEMORI SDK CONFIGURATION
# ============================================================================
MEMORI_VECTOR_DIM=1536
MEMORI_SIMILARITY_THRESHOLD=0.7
MEMORI_MAX_MEMORIES=1000

# ============================================================================
# RATHENA BRIDGE CONFIGURATION
# ============================================================================
RATHENA_BRIDGE_URL=http://localhost:8080
RATHENA_BRIDGE_TIMEOUT=10

# ============================================================================
# PERFORMANCE TUNING
# ============================================================================
MAX_CONCURRENT_NPCS=100
NPC_DECISION_INTERVAL=10
WORLD_UPDATE_INTERVAL=60

# ============================================================================
# MONITORING
# ============================================================================
PROMETHEUS_ENABLED=true
PROMETHEUS_PORT=9090

# ============================================================================
# DEVELOPMENT
# ============================================================================
DEBUG=true
RELOAD=true

